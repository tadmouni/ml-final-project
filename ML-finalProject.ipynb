{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ML_finalProject.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "FZUUZbvdkIff"
      },
      "source": [
        "#Load Dataset\n",
        "def loadDataset():  \n",
        "  df = pd.read_csv('vanityPlates.csv')\n",
        "\n",
        "  return df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PM7_WIYEkxk5"
      },
      "source": [
        "# Split DataFrame into Data and Target\n",
        "def getDataTargetSets(df):\n",
        "  temp = df\n",
        "  status_list = df['status']\n",
        "  target_df = pd.DataFrame(status_list, columns = ['status']) \n",
        "  #target_df = df['status']\n",
        "  temp.drop(['status'], axis=1 , inplace=True)\n",
        "  #dfs = np.split(df, [4], axis=1)\n",
        "\n",
        "  return temp, target_df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5I71x4AvlIce"
      },
      "source": [
        "# Check profanity probability of each vanity plate\n",
        "def runProfanityCheck(df):\n",
        "  plateArr = df['plate']\n",
        "  plate_prof_probs = []\n",
        "  for plate in plateArr:\n",
        "    plate_prof_probs.append(predict_prob([plate])[0])\n",
        "  return plate_prof_probs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yW5jQnD5-qme"
      },
      "source": [
        "# Load bad_words text file\n",
        "def getOffensiveWords():\n",
        "  with open('offensive_words.txt') as f:\n",
        "      offensive_word_list = [word.upper() for line in f for word in line.split()]\n",
        "  f.close()\n",
        "  #offensive_words = ' '.join(word[0] for word in offensive_word_list)\n",
        "  #print(offensive_word_list)\n",
        "  return offensive_word_list"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cAlitbDk8JAu"
      },
      "source": [
        "# String match with offensive words\n",
        "!pip install fuzzywuzzy\n",
        "from fuzzywuzzy import fuzz\n",
        "\n",
        "def get_offensive_plate_ratio(df):\n",
        "  offensive_word_list = getOffensiveWords()\n",
        "  plateArr = df['plate']\n",
        "  plate_offensive_ratios = []\n",
        "  \n",
        "  for plate in plateArr:\n",
        "    off_ratio = 0\n",
        "    offensive_ratios = []\n",
        "    for off_word in offensive_word_list:\n",
        "      off_ratio = fuzz.ratio(plate, off_word)\n",
        "      offensive_ratios.append(off_ratio)\n",
        "      if off_ratio == 100:\n",
        "        break\n",
        "    plate_offensive_ratios.append(max(offensive_ratios))\n",
        "\n",
        "  return plate_offensive_ratios"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EvbEeJvHmwnM"
      },
      "source": [
        "# Perform one hot encoding for vanity plate text\n",
        "def one_hot_encode_plate(df):\n",
        "  alphaNumChars=\"ABCDEFGHIJKLMNOPQRSTUVWXYZ0123456789@#$%^&* \"\n",
        "  plate_texts = df['plate'].values\n",
        "  for char in alphaNumChars:\n",
        "    newPlateColName = \"plate_\"+char\n",
        "    plateChars = []\n",
        "    for plate in plate_texts:\n",
        "      if char in plate:\n",
        "        plateChars.append('1')\n",
        "      else:\n",
        "        plateChars.append('0')\n",
        "    df[newPlateColName] = plateChars\n",
        "\n",
        "  return df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "144D6AkGnPTI"
      },
      "source": [
        "# Perform one hot encoding for review reason code\n",
        "def one_hot_encode_review_reason_code(df):\n",
        "\n",
        "  df = pd.concat([df, pd.get_dummies(df['review_reason_code'], prefix='review_reason_code')], axis=1)\n",
        "  df.drop(['review_reason_code'], axis=1, inplace=True)\n",
        "  \n",
        "  return df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lKHPEPivtRRW"
      },
      "source": [
        "def train_test_split(X, y):\n",
        "  from sklearn.model_selection import train_test_split\n",
        "\n",
        "  X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state = 42)\n",
        "  print(\"No. of samples in X_train: \", len(X_train))\n",
        "  print(\"No. of samples in X_test: \", len(X_test))\n",
        "  print(\"No. of samples in y_train: \", len(y_train))\n",
        "  print(\"No. of samples in y_test: \", len(y_test))\n",
        "\n",
        "  return X_train, X_test, y_train, y_test"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "an6A-aAKka4O",
        "collapsed": true
      },
      "source": [
        "!pip install profanity-check\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from profanity_check import predict, predict_prob\n",
        "\n",
        "# Load the dataset\n",
        "df = loadDataset()\n",
        "\n",
        "# Get Profanity Probability\n",
        "plate_prof_probs = runProfanityCheck(df)\n",
        "df['plate_profanity'] = plate_prof_probs\n",
        "\n",
        "# Get plate text offensive ratio\n",
        "\n",
        "#plate_offensive_ratios = get_offensive_plate_ratio(df)\n",
        "with open('offensivePlateRatios.txt') as f:\n",
        "  plate_offensive_ratios = [word.upper() for line in f for word in line.split()]\n",
        "f.close()\n",
        "\n",
        "print(plate_offensive_ratios)\n",
        "df['plate_offensive_ratio'] = plate_offensive_ratios\n",
        "\n",
        "# One-Hot Encode Vanity Plates - Character level\n",
        "df = one_hot_encode_plate(df)\n",
        "\n",
        "# One-Hot Encode Review Reason Code\n",
        "df = one_hot_encode_review_reason_code(df)\n",
        "\n",
        "#cleanup: drop string columns so that PCA will work \n",
        "df.drop(['plate', 'customer_meaning', 'reviewer_comments'], axis=1, inplace=True)\n",
        "print(df.shape)\n",
        "\n",
        "# Making new data frame with dropped NA values\n",
        "new_df = df.dropna(axis = 0, how ='any')\n",
        "  \n",
        "# comparing sizes of data frames \n",
        "print(\"Old data frame length:\", len(df), \"\\nNew data frame length:\",  \n",
        "       len(new_df), \"\\nNumber of rows with at least 1 NA value: \", \n",
        "       (len(df)-len(new_df))) \n",
        "\n",
        "#Split dataset into data and target\n",
        "data_df, target_df = getDataTargetSets(new_df)\n",
        "\n",
        "data_df.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5t_1vFVD0ldi"
      },
      "source": [
        "# Status count in dataset\n",
        "print(target_df['status'].value_counts())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TOOuxJZCvqkO"
      },
      "source": [
        "# Split Dataset into train and test\n",
        "X = data_df.to_numpy()\n",
        "y = target_df.to_numpy()\n",
        "\n",
        "print(X)\n",
        "print(y)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PuGDhbVU3EN-"
      },
      "source": [
        "#determine number of features with PCA evaluating on simple SVM model with stratified cross validation\n",
        "\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "numfeatures = []\n",
        "recall_pca = []\n",
        "for features in [100, 80, 60, 40, 35, 30, 25, 20, 15, 10, 5, 1]: \n",
        "  #dimensionality reduction\n",
        "  pca = PCA(n_components=features)\n",
        "  pca.fit(X_train)\n",
        "  X_train_reduced = pca.transform(X_train)\n",
        "  #svm\n",
        "  svm_pca = SVC()\n",
        "  svm_pca_recalls = cross_val_score(svm_pca, X_train_reduced, y_train, cv=5, scoring='recall_micro')\n",
        "  svm_pca_recalls_avg = svm_pca_recalls.mean()\n",
        "  #NB\n",
        "  #NB_pca = GaussianNB()\n",
        "  #NB_pca_recalls = cross_val_score(NB_pca, X_train_reduced, y_train, cv=5, scoring='recall_micro')\n",
        "  #NB_pca_recalls_avg = NB_pca_recalls.mean()\n",
        "  #Decision tree\n",
        "  #DT_pca = DecisionTreeClassifier()\n",
        "  #DT_pca_recalls = cross_val_score(DT_pca, X_train_reduced, y_train, cv=5, scoring='recall_weighted')\n",
        "  #DT_pca_recalls_avg = DT_pca_recalls.mean()\n",
        "  numfeatures.append(features)\n",
        "  recall_pca.append(svm_pca_recalls_avg)\n",
        "  #np.ravel(y_train,order='C')\n",
        "\n",
        "plt.plot(numfeatures, recall_pca)\n",
        "plt.xlabel(\"number of features\")\n",
        "plt.ylabel(\"recall\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "puicz4q9kdJd"
      },
      "source": [
        "# Perform 5-Fold Stratified cross-validation\n",
        "\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "\n",
        "skFold = StratifiedKFold(n_splits = 5)\n",
        "\n",
        "#Decision Tree classifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "best_score_dt = 0\n",
        "criterion_settings = [\"gini\", \"entropy\"]\n",
        "depth_settings = range(5, 30)\n",
        "\n",
        "for criterion_value in criterion_settings:\n",
        "  for depth_value in depth_settings:\n",
        "    # Build model\n",
        "    dTreeClassifier = DecisionTreeClassifier(criterion=criterion_value, max_depth=depth_value)\n",
        "\n",
        "    fold_recall_dt = cross_val_score(dTreeClassifier, X_train, y_train, scoring='recall_macro', cv=skFold)\n",
        "    #print(\"Cross_validation_score: \\n{}\".format(fold_recall_dt.mean()))\n",
        "    score = fold_recall_dt.mean()\n",
        "    if score > best_score_dt:\n",
        "      best_param_dt = {'criterion': criterion_value, 'max_depth': depth_value}\n",
        "      best_score_dt = score\n",
        "\n",
        "print(best_param_dt)\n",
        "print(best_score_dt)\n",
        "# print(data_df.shape)\n",
        "# print(target_df.shape)\n",
        "# print(target_df['status'].value_counts())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mc0MYO8Z_5ID"
      },
      "source": [
        "# Tune hyperparameters for SVM using stratified 5-fold cross-validation\n",
        "from sklearn.svm import SVC\n",
        "\n",
        "best_score_svm = 0\n",
        "degree_settings = range(2,5)\n",
        "gamma_settings = [\"auto\", \"scale\"]\n",
        "c_settings = [1e-6, 0.00001, 0.0001, 0.001]\n",
        "\n",
        "for degree_value in degree_settings:\n",
        "  for gamma_value in gamma_settings:\n",
        "    for c_value in c_settings:\n",
        "    # Build model\n",
        "      svmClassifier = SVC(kernel=\"poly\", degree=degree_value, gamma=gamma_value, C=c_value)\n",
        "\n",
        "      fold_recall_svm = cross_val_score(svmClassifier, X_train, np.ravel(y_train,order='C'), scoring='recall_macro', cv=skFold)\n",
        "      #print(\"Cross_validation_score: \\n{}\".format(fold_recall_svm.mean()))\n",
        "      score = fold_recall_svm.mean()\n",
        "      if score > best_score_svm:\n",
        "        best_param_svm = {'degree': degree_value, 'gamma': gamma_value, 'C': c_value, 'kernel':'poly'}\n",
        "        best_score_svm = score\n",
        "\n",
        "print(best_score_svm)\n",
        "print(best_param_svm)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_gB_3C5O7iSi"
      },
      "source": [
        "# Train Naive Bayes classifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "\n",
        "gaussian_model = GaussianNB()\n",
        "fold_recall_nb = cross_val_score(gaussian_model, X_train, np.ravel(y_train,order='C'), scoring='recall_macro', cv=skFold)\n",
        "score_nb = fold_recall_nb.mean()\n",
        "print(score_nb)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h5uEhK8pDn62"
      },
      "source": [
        "# Retrain KNN\n",
        "kClassifier = KNeighborsClassifier(**best_param_knn)\n",
        "kClassifier.fit(X_train, y_train)\n",
        "\n",
        "#Retrain DecisionTree\n",
        "dTreeClassifier = DecisionTreeClassifier(**best_param_dt)\n",
        "dTreeClassifier.fit(X_train, y_train)\n",
        "\n",
        "#Retrain SVM\n",
        "svmClassifier = SVC(**best_param_svm)\n",
        "svmClassifier.fit(X_train, y_train)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YBZE9lpiD4Kr"
      },
      "source": [
        "# Experiment 3 - Ensemble Learning\n",
        "from sklearn.ensemble import VotingClassifier\n",
        "from sklearn.ensemble import BaggingClassifier\n",
        "\n",
        "# Majority Vote Classifier\n",
        "enClf = VotingClassifier(estimators=[('dt', dTreeClassifier),('svm', svmClassifier),('gnb', gaussian_model)], voting='hard')\n",
        "fold_precision_mvote = cross_val_score(enClf, X_train, y_train, cv=skFold, scoring='precision_macro')\n",
        "fold_recall_mvote = cross_val_score(enClf, X_train, y_train, cv=skFold, scoring='recall_macro')\n",
        "print(\"Majority Vote Classifier\")\n",
        "print(fold_precision_mvote)\n",
        "print(fold_recall_mvote)\n",
        "print(fold_precision_mvote.mean())\n",
        "print(fold_recall_mvote.mean())\n",
        "\n",
        "# Bagging classifier for DecisionTree\n",
        "baggingClf_dt = BaggingClassifier(dTreeClassifier)\n",
        "\n",
        "fold_precision_bag_dt = cross_val_score(baggingClf_dt, X_train, y_train, cv=skFold, scoring='precision_macro')\n",
        "fold_recall_bag_dt = cross_val_score(baggingClf_dt, X_train, y_train, cv=skFold, scoring='recall_macro')\n",
        "print(\"Bagging Classifier - Decision Tree\")\n",
        "print(fold_precision_bag_dt)\n",
        "print(fold_recall_bag_dt)\n",
        "print(fold_precision_bag_dt.mean())\n",
        "print(fold_recall_bag_dt.mean())\n",
        "\n",
        "# Bagging classifier for SVM\n",
        "baggingClf_svm = BaggingClassifier(svmClassifier)\n",
        "fold_precision_bag_svm = cross_val_score(baggingClf_svm, X_train, y_train, cv=skFold, scoring='precision_macro')\n",
        "fold_recall_bag_svm = cross_val_score(baggingClf_svm, X_train, y_train, cv=skFold, scoring='recall_macro')\n",
        "print(\"Bagging Classifier - SVM\")\n",
        "print(fold_precision_bag_svm)\n",
        "print(fold_recall_bag_svm)\n",
        "print(fold_precision_bag_svm.mean())\n",
        "print(fold_recall_bag_svm.mean())\n",
        "\n",
        "# Bagging classifier for NaiveBayesGaussian\n",
        "baggingClf_gnb = BaggingClassifier(gaussian_model)\n",
        "fold_precision_bag_gnb = cross_val_score(baggingClf_gnb, X_train, y_train, cv=skFold, scoring='precision_macro')\n",
        "fold_recall_bag_gnb = cross_val_score(baggingClf_gnb, X_train, y_train, cv=skFold, scoring='recall_macro')\n",
        "print(\"Bagging Classifier - NaiveBayes\")\n",
        "print(fold_precision_bag_gnb)\n",
        "print(fold_recall_bag_gnb)\n",
        "print(fold_precision_bag_gnb.mean())\n",
        "print(fold_recall_bag_gnb.mean())\n",
        "\n",
        "\n",
        "# AdaBoost classifier for DecisionTree\n",
        "adabooster_dt = AdaBoostClassifier(base_estimator=dTreeClassifier, n_estimators = 50)\n",
        "fold_precision_boost_dt = cross_val_score(adabooster_dt, X_train, y_train, cv=skFold, scoring='precision_macro')\n",
        "fold_recall_boost_dt = cross_val_score(adabooster_dt, X_train, y_train, cv=skFold, scoring='recall_macro')\n",
        "print(\"Boosting Classifier - DecisionTree\")\n",
        "print(fold_precision_boost_dt)\n",
        "print(fold_recall_boost_dt)\n",
        "print(fold_precision_boost_dt.mean())\n",
        "print(fold_recall_boost_dt.mean())\n",
        "\n",
        "# AdaBoost classifier for SVM\n",
        "adabooster_svm = AdaBoostClassifier(base_estimator=svmClassifier, n_estimators = 50)\n",
        "fold_precision_boost_svm = cross_val_score(adabooster_svm, X_train, y_train, cv=kfold, scoring='precision_macro')\n",
        "fold_recall_boost_svm = cross_val_score(adabooster_svm, X_train, y_train, cv=kfold, scoring='recall_macro')\n",
        "print(\"Boosting Classifier - SVM\")\n",
        "print(fold_precision_boost_svm)\n",
        "print(fold_recall_boost_svm)\t\n",
        "\n",
        "# AdaBoost classifier for NaiveBayes\n",
        "adabooster_gnb = AdaBoostClassifier(base_estimator=gaussian_model, n_estimators = 50)\n",
        "fold_precision_boost_gnb = cross_val_score(adabooster_gnb, X_train, y_train, cv=kfold, scoring='precision_macro')\n",
        "fold_recall_boost_gnb = cross_val_score(adabooster_gnb, X_train, y_train, cv=kfold, scoring='recall_macro')\n",
        "print(\"Boosting Classifier - NaiveBayes\")\n",
        "print(fold_precision_boost_gnb)\n",
        "print(fold_recall_boost_gnb)\n",
        "print(fold_precision_boost_gnb.mean())\n",
        "print(fold_recall_boost_gnb.mean())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IcJynT9-Ff03"
      },
      "source": [
        "# experiment 4: train/determine hyperparameters for MLPClassifier \n",
        "from sklearn.neural_network import MLPClassifier\n",
        "\n",
        "#optimize hidden layers and # of neurons\n",
        "recall_1hl = []\n",
        "recall_2hl = []\n",
        "recall_3hl = []\n",
        "n_neurons_per_l = []\n",
        "for n_hidden_units in [10, 25, 50, 100]:\n",
        "  n_neurons_per_l.append(n_hidden_units)\n",
        "  #one hidden layer\n",
        "  mlp1 = MLPClassifier(hidden_layer_sizes= [n_hidden_units], max_iter=50)\n",
        "  mlp1_recalls = cross_val_score(mlp1, X_train, y_train, cv=5, scoring='recall_macro')\n",
        "  mlp1_recalls_avg = mlp1_recalls.mean()\n",
        "  recall_1hl.append(mlp1_recalls_avg)\n",
        "  #two hidden layers\n",
        "  mlp2 = MLPClassifier(hidden_layer_sizes= [n_hidden_units, n_hidden_units], max_iter=50)\n",
        "  mlp2_recalls = cross_val_score(mlp2, X_train, y_train, cv=5, scoring='recall_macro')\n",
        "  mlp2_recalls_avg = mlp2_recalls.mean()\n",
        "  recall_2hl.append(mlp2_recalls_avg)\n",
        "  #three hidden layers\n",
        "  mlp3 = MLPClassifier(hidden_layer_sizes= [n_hidden_units, n_hidden_units, n_hidden_units], max_iter=50)\n",
        "  mlp3_recalls = cross_val_score(mlp3, X_train, y_train, cv=5, scoring='recall_macro')\n",
        "  mlp3_recalls_avg = mlp3_recalls.mean()\n",
        "  recall_3hl.append(mlp3_recalls_avg)\n",
        "\n",
        "\n",
        "#plot\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "plt.plot(n_neurons_per_l, recall_1hl, label=\"1 hidden layer\")\n",
        "plt.plot(n_neurons_per_l, recall_2hl, label=\"2 hidden layers\")\n",
        "plt.plot(n_neurons_per_l, recall_3hl, label=\"3 hidden layers\")\n",
        "plt.xlabel(\"Neurons per layer\")\n",
        "plt.ylabel(\"Recall\")\n",
        "plt.legend()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vYFkTn7DNCxM"
      },
      "source": [
        "'hidden_layer_sizes': [x for x in itertools.product((10,20,30,40,50,100),repeat=3)]\n",
        "\n",
        "\n",
        "parameters={\n",
        "'learning_rate': [\"constant\", \"invscaling\", \"adaptive\"],\n",
        "'hidden_layer_sizes': [(100,1), (100,2), (100,3)],\n",
        "'alpha': [10.0 ** -np.arange(1, 7)],\n",
        "'activation': [\"logistic\", \"relu\", \"Tanh\"]\n",
        "}\n",
        "\n",
        "clf\n",
        "= gridSearchCV(estimator=MLPClassifier,param_grid=parameters,n_jobs=-1,verbose=2,cv=10)\n",
        "# experiment 4: train/determine hyperparameters for MLPClassifier \n",
        "from sklearn.neural_network import MLPClassifier\n",
        "\n",
        "#optimize hidden layers and # of neurons\n",
        "recall_1hl = []\n",
        "recall_2hl = []\n",
        "recall_3hl = []\n",
        "n_neurons_per_l = []\n",
        "for n_hidden_units in [10, 25, 50, 100]:\n",
        "  n_neurons_per_l.append(n_hidden_units)\n",
        "  #one hidden layer\n",
        "  mlp1 = MLPClassifier(hidden_layer_sizes= [n_hidden_units], max_iter=50)\n",
        "  mlp1_recalls = cross_val_score(mlp1, X_train, y_train, cv=5, scoring='recall_macro')\n",
        "  mlp1_recalls_avg = mlp1_recalls.mean()\n",
        "  recall_1hl.append(mlp1_recalls_avg)\n",
        "  #two hidden layers\n",
        "  mlp2 = MLPClassifier(hidden_layer_sizes= [n_hidden_units, n_hidden_units], max_iter=50)\n",
        "  mlp2_recalls = cross_val_score(mlp2, X_train, y_train, cv=5, scoring='recall_macro')\n",
        "  mlp2_recalls_avg = mlp2_recalls.mean()\n",
        "  recall_2hl.append(mlp2_recalls_avg)\n",
        "  #three hidden layers\n",
        "  mlp3 = MLPClassifier(hidden_layer_sizes= [n_hidden_units, n_hidden_units, n_hidden_units], max_iter=50)\n",
        "  mlp3_recalls = cross_val_score(mlp3, X_train, y_train, cv=5, scoring='recall_macro')\n",
        "  mlp3_recalls_avg = mlp3_recalls.mean()\n",
        "  recall_3hl.append(mlp3_recalls_avg)\n",
        "\n",
        "\n",
        "#plot\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "plt.plot(n_neurons_per_l, recall_1hl, label=\"1 hidden layer\")\n",
        "plt.plot(n_neurons_per_l, recall_2hl, label=\"2 hidden layers\")\n",
        "plt.plot(n_neurons_per_l, recall_3hl, label=\"3 hidden layers\")\n",
        "plt.xlabel(\"Neurons per layer\")\n",
        "plt.ylabel(\"Recall\")\n",
        "plt.legend()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}